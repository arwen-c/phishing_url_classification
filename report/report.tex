\documentclass{article}
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
\usepackage[preprint]{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}
\usepackage{cleveref}
\usepackage{enumerate}
\usepackage{listings}         % colors
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}


\title{Machine Learning Project Report}

\author{
    Jop Zitman 2023280072\\
    Department of Computer Science\\
    Tsinghua University\\
    Beijing, China \\
    \texttt{lilw23@mails.tsinghua.edu.cn} \\
    \And
    Lauriane Teyssier 2023280008\\
    Department of Computer Science\\
    Tsinghua University\\
    Beijing, China \\
    \texttt{yell23@mails.tsinghua.edu.cn} \\
}

% Document
\begin{document}

    \maketitle

    \begin{abstract}
        The increasing sophistication and frequency of phishing attacks pose a significant threat in the digital era, highlighting the need for advanced detection methodologies.
        This study explores the application of machine learning and deep learning techniques to classify phishing URLs in the wake of an alarming escalation in cyber threats.
        Our research encompasses a comprehensive evaluation of various machine learning and deep learning models, including Logistic Regression, Support Vector Machine, Naive Bayes, Nearest Neighbors, and sophisticated neural network architectures like CNNs and LSTMs. We also delve into the realm of Large Language Models (LLMs) for phishing URL detection.

        By establishing a benchmark on a unified dataset, we aim to provide an objective comparison of different models, thereby contributing significantly to the field of cybersecurity.

        The outcomes of our research not only shed light on the efficacy of various models in phishing URL detection but also offer insights into the future directions for enhancing the accuracy and efficiency of such systems.
    \end{abstract}

    \newpage
    \tableofcontents
    \newpage


%    \section{Jop dump}
%
%    https://www.kaggle.com/datasets/shawon10/url-classification-dataset-dmoz/data
%    https://utatds.github.io/2017-01-18-URL-classification-using-DMOZ-data/
%    https://github.com/stanfordnlp/GloVe
%    https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/
%    https://huggingface.co/elftsdmr/malware-url-detect

    % TODO read all the articles and provide their different results and our comparison


    \section{Problem description and motivation}\label{sec:problem-description-and-motivation}
%    What’s the background of the problem?
%    Is it theory-driven, or deeply rooted in some useful application situations?
%    Is it important or necessary?
%    What impact will it bring if you finally solve it?

    The motivation for using machine learning to classify phishing URLs gains urgency against the backdrop of an alarming rise in cyber threats.
    Phishing, a deceptive practice where attackers pose as legitimate entities to harvest sensitive information, has not only intensified in sophistication but also in frequency.
    The Anti-Phishing Working Group's (APWG) report for the fourth quarter of 2022 provides a stark illustration: over 4.7 million phishing attacks were recorded in 2022, marking a year-over-year increase exceeding 150\% \cite{PhishingActivityTrendsReport}.
    The final quarter of that year alone witnessed 1,350,037 attacks, slightly up from the previous quarter's record of 1,270,883 incidents, indicating a persistent and escalating threat.
    APWG records a constant augmentation of the threat, as shown below:

    \begin{figure}
        \centering
        \includegraphics{report_img/shartincreasingphishing}
        \caption{Evolution of phishing from 2019 to 2022 according to APWG\cite{PhishingActivityTrendsReport}}
        \label{fig:figure}
    \end{figure}

    The financial sector bore the brunt of these attacks, accounting for 27.7\% of all phishing incidents.
    Phishing attempts against webmail and software-as-a-service (SAAS) providers were also notable, comprising 17.7\% of the attacks.
    These attacks, which involve impersonating trusted parties to manipulate victims into transferring funds or revealing sensitive data, have led to losses in the billions.
    In the fourth quarter of 2022 alone, the average amount requested in wire transfer BEC attacks soared to \$132,559, marking a 41\% increase from the previous quarter.

    In addition, the FBI’s Internet Crime Complaint Center reported a near doubling of phishing incidents from 2019 to 2020.

    The methods employed in these attacks are diverse.
    The fourth quarter of 2022 saw advance fee fraud scams surpassing gift card requests as the most popular method, accounting for 39\% of all attacks.
    This shift underscores the adaptability and evolving strategies of attackers.
    Gift cards, particularly Amazon and Apple cards, remained popular among scammers, with 60\% favoring Amazon cards.

    Historically, phishing attempts were more transparent and easier to spot due to their general approach and clear warning signs.
    However, the integration of AI has led to more subtle and customized phishing strategies, using personal information to boost their believability.
    This shift calls for a detection system that is both intelligent and adaptive, capable of keeping pace with these evolving threats.

    Today's method of detecting phishing URLs mainly rely on blacklists, which are lists of known phishing URLs.
    These are largely implemented in navigators.
    However, these methods lack in speed detection for being more efficient.
    \cite{PhishingExperimentalBlackLists2009} reports after empirical analysis than less than 20\% of their phishing campaigns have been caught.
    \cite{PhishingBlackLists} reports only 12\% overlap between two of the main phishing blacklists.

    This landscape of escalating and evolving phishing attacks underscores the critical need for advanced detection methods, including the application of machine learning for phishing URL classification.


    \section{Related works}\label{sec:related-works}

    In the realm of URL-based phishing detection, a rich literature addresses each part of the detection process, from the creation of set of databases to comparison metrics between the methodologies, including comparison of classification algorithm or data pre-processing.
    The approach can be divided into two main groups, the authors focusing on Machine Learning and and those proposing an approach based on deep learning.
    We will highlight references of both approaches.

    \subsection{Machine Learning based approaches}\label{subsec:machine-learning-based-approaches}

    \begin{itemize}

        \item An phishing URL detection method (\cite{PhishingURLDetection}) compares different Machine Learning classification algorithm.
        Their data processing involves first the detection of words through 17 NLP handcrafted features.
        It then relies on a Markov Chain Model to identify random word.
        The classification is based on detecting Typosquatting and employs various algorithms like Naive Bayes, Random Forest, kNN, Adaboost, K-star, SMO, and Decision Tree.
        The study reached 97.20\% of accuracy with Weka's RFC (Random Forest Classifier) on a 10\% sub-sample from the Ebbu2017 dataset.

        \item In their paper\cite{PhishSafe}, Jain and Gupta developed an anti-phishing system employing 14 handcrafted URL descriptors.
        They conducted tests using two classifiers: Naive Bayes, which achieved an accuracy of 76.87\%, and Support Vector Machine, demonstrating a higher accuracy of 91.28\%.

        \item The study presented in\cite{LexicalFeatureSelection} implemented a classification system based on lexical features extracted from URLs. Their methodology involved a feature extraction from URLs, the selection of the most relevant features through chi-square feature selection, and the utilization of various machine learning algorithms for classification.
        With nine selected features and a Random Forest (RF) classifier, they achieved their best accuracy of 98.57%.

    \end{itemize}

    \subsection{Deep Learning based approaches}\label{subsec:deep-learning-based-approaches}

    \begin{itemize}
        \item  The Spanish national institute for security classifies in\cite{PhishingLoginURLDetection} login form URLs into malicious or legitimate categories through two distinct techniques.
        The first technique employs machine learning with text pre-processing, including symbol-based word separation, text conversion into feature vectors (use 38 features, among them the frequency of symbols, the number of digits, length, \ldots), and classification.
        Eight different classifiers have been used for comparison.
        The second technique utilizes deep learning, specifically a convolutional neural network, with no text preprocessing.
        The results show that the best performance is archived for the machine learning NLP frequency feature extraction combined with Logistic Regression (accuracy of 96.50\%).


        \item \cite{EfficientDeepLearningPhishingDetection} introduced three Deep Learning models for classifying phishing URLs, utilizing ten of the most relevant handcrafted features out of a total of 18, which included characteristics like the number of dots, length, and the presence of HTTPS. These models included Convolutional Neural Network (CNN), Deep Neural Network (DNN), and Long Short-Term Memory (LSTM). Among these, the LSTM model achieved the best performance, boasting an impressive accuracy of 99.57\%.

        \item An RCNN model to classify phishing URLs is compared with different machine learning common approaches (Naïves Bayes, Logistic Regression, random forest and XGBoost) on four different types of features (hand crafted, character embedding, character level TF-IDF and character level count vector features)\cite{CharacterLevelCNN}.
        The URL is used as input for a tokenizer and then then transformed into a matrix using one-hot encoding.
        Their RCNN model obtained 95:02\% accuracy.

    \end{itemize}

    \subsection{Large Language Models}\label{subsec:large-language-models}
    PhishBert~\cite{PhishBert} is a Bert based model that is pretrained with the manipulated token detection objective on 3 billion URLs.
    A classification layer is then added and fine-tuned on a smaller dataset with the objective of detecting phishing URLs.
    The model achieves an unspecified, but close to 100 percent accuracy depending on the amount of data in their pre-training stage.

    \subsection{Datasets}\label{subsec:datasets}

    There exists multiple crowdsource based phasing URL collection applications.
    The main ones are PhishTank~\cite{PhishTank}, OpenPhish~\cite{OpenPhish}, and PhishRepo~\cite{PhishRepo}.
    However, due to the relatively short-lived nature of phishing sites after a phishing report, all of these do regular data cleanups.
    They offer a data feed that you can subscribe too, meaning that if you want to create a dataset, you have to subscribe to the feed for a while, where back-filling is not completely possible.
    Another popular dataset is Google SafeBrowsing\cite{GoogleSafeBrowsing}, which is integrated into several browsers.
    Unfortunately, they only expose a query API to check a URL for legitimacy, rather than exposing their entire dataset.

    JPCERT/CC is a Computer Security Incident Response Team established in Japan.
    The organization coordinates with network service providers, security vendors, government agencies, as well as the industry associations\cite{JPCertCC}.
    In 2022, they released a URL dataset of phishing sites confirmed from January 2019 to June 2022\cite{JPCertCCDataset}.

    Another dataset published on GitHub contains about 750k malicious URLs and 750k benign URLs\cite{VisualizingRNNInURLDetection}.
    The malicious set is collected by following the aforementioned PhishTank for a while.
    For legitimate URLs, they followed the top Alexa websites (an organization tracking most commonly visited websites).

    \subsubsection{Login page based dataset}\label{subsubsec:login-page-based-dataset}
    In\cite{PhishingLoginURLDetection}, it is mentioned that ``Existing URL datasets use the homepage URL from well-known websites as the legitimate.
    However, we think that the challenge is to determine if a login form of a website is legitimate or phishing.
    From our perspective, and to the best of our knowledge, publicly available datasets are not reflecting conditions that represent some real problems for phishing URL detection.''
    This raises the question of whether the models built on home page-based legitimate websites are even valid (comparing apples and pears).
    In their dataset (PILU-90K), they only include URLs of pages which contain password fields (suggesting it's a login page).

    \subsubsection{Additional data}\label{subsubsec:additional-data}
    These solutions have so far only looked at the URLs, however some datasets also include further data of each URL, such as the HTML title, body, or even a screenshot.
    For example, the ``Phishing Websites Dataset''\cite{VisualizingRNNInURLDetection} contains the entire HTML of every URL, largely increasing the dataset size and the potential solutions of solving the problem.
    You can imagine that the content of a webpage reveals much about a website's intent.

    Such datasets are either constructed using DMOZ, CommonCrawl, or by manual fetching (using headless browsers\cite{PhishingLoginURLDetection} or simple HTTP clients).%add citation for http client
    DMOZ~\cite{DMOZ} is a large human-edited web directory, which has been used in the past to create a dataset of legitimate URLs. However, this project has been discontinued in 2017, and the data is no longer maintained.
    CommonCrawl~\cite{CommonCrawl} is similar to DMOZ. It is a non-profit organization that crawls the web and makes the data publicly available.

    There are many more datasets to be found, but most of them are derivatives of the aforementioned datasets.
    For example Ebbu2017~\cite{EBBU2017} and PWD2016~\cite{PWD2016}.

%    Different deep learning model have been used to classify websites.
%    Two main approaches occurs when trying to analyze the web: classifying a website by analyzing its content or relying on the URL to classify it
%
%    Some are directly linked
%
%    Papers detecting phishing URL for example from 2022
%    https://ieeexplore.ieee.org/document/9759382.
%    In their state of the art, the author evokes different classification machine learning algorithm:
%    - Buber et al. [25] 17 NLP (Natural Language Processing) handcrafted
%    features such as the number of sub-domains, random words,
%    digits, special characters and length measurements over the
%    URL words
%
%    StringToWordVector


    \section{Proposed method}\label{sec:proposed-method}

    \subsection{Approach}\label{subsec:approach}


%    Method chosen: offline URL classification
%    Advantages of the method chosen: fast computation, language independent
%
%    We aim to find the bests performances on classifying malicious from legitimate URL by implementing comparative machine learning and deep learning approaches.
%
%    Regarding machine learning, the modeling process consists in three steps: pre processing (converting URL into text), extraction of feature and classification.
%    We want to compare the performance of different classifiers, by optimizing simultaneously the construction of the feature and their selection.
%
%    Regarding deep learning, the performance mainly depends on the layer architecture.
%    Our objective is to try replicating one or two neurons architectures among the more performing on previous works.
%    Some additional data treatment may be done.
%
%    Very rich literature on the subject, we want to benchmark them and compare them on the same dataset.
%
%    What are the motivations for you to choose it?
%    Which datasets do you propose to
%    experiment on?
%    What baseline approaches do you plan to compare with?
%    How do you implement your proposed method based on the dataset?
%    It is ok to change and improve it later but now try to describe it as detailed as possible.
%
%    Inspired from different techniques and analysis used to classify URL, we will try to identify the category of website the URL relates to
%
%    - test of different ML algorithm for performance comparison (linear regression, deep neural network, modification of pre train text analysis model) to compare and select the best model
%
%    - test of different datasets, and the results of training on one/test on the other (different datasets available on kaggle and on the net) - possibility on comparing the results depending on the date/epoque of the dataset, the countries they are from, \ldots and see what comes up
%
%    - what do the domain name tells us about the website?
%    do we have some better performances analyzing some complete URL? If yes, how much does it increases the performance of the model?
%
%    - Different approaches : making clusters with imposing the categories that we expect, or seeing what categories it makes on its own, by clustering and finding out what each clusters is linked with


    A first approach of this URL classification problem could try a new machine learning method and try to apply it to this specific problem and comparing it to the different results that the literature.
    This is very interesting to get in depth with one specific model.
    However, we were intrigued by the different results that studied could have on same models (for example machine learning models) on similar datasets.
    From all these studies, it seemed difficult to establish any ranking or argument comparison of the different models, since each one had the best results on its new introduced approach.
    This is the reason why we chose to establish a benchmark of the different solutions.
    By implementing them on the same dataset, relying on the different studies from the literature, we could establish a more objective classification.
    Another advantage for us as student of this approach is to develop our critical sens of studies (learn to detect what can be improved from a study, from what is strong argumentation) and to get familiar with these different approaches.

    We explored these different models:
    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{report_img/modelspresentation}
        \caption{}
        \label{fig:model_presentation}
    \end{figure}

    \subsection{Dataset}\label{subsec:dataset}
    In our initial project proposal, we intended to utilize the PILU-90K~\cite{PhishingURLDetection}.
    However, accessing this dataset proved to be challenging due to the requirement of a formal request by a professor supervising the project.
    Consequently, we shifted our focus to the most extensive dataset identified in our research, specifically the one proposed in~\cite{VisualizingRNNInURLDetection}.
    Among the available datasets with sufficient volume for neural network model training, this particular dataset is the most recent and provides open access.

    Originally, this dataset is tailored for training Neural Network models, with its data already encoded in integer array formats.
    To adapt this dataset for broader Machine Learning applications, we undertook a preprocessing step to convert these integer arrays back into textual URL formats.
    Furthermore, in our exploration of neural network methodologies, we are not only utilizing the original vectorization techniques of the dataset but also experimenting with alternative vectorization strategies.

    We've thought about manually generating datasets, in case we are unable to find public datasets.
    For instance, we could extract malicious URLs from phishing e-mail datasets.
    We could also manually gather URLs from PhishTank, OpenPhish, or PhishRepo, but we expect that the few weeks that we may be able to gather URLs will not give us a large enough dataset, also considering the need for verification and the unknown project grade contribution of dataset generation.

    In addition, if we want to follow the methodology described in ~\cite{PhishingLoginURLDetection}, we would have to manually crawl hundreds of thousands of web pages using headless browsers in order to find the login page.
    We did not consider this option because of the time and resources required, especially since browsers take many resources and are hard to parallelize.
    We also expected issues with running into Web Application Firewalls when visiting so many websites, further decreasing the quality of our dataset.

    \subsubsection{Preprocessing}\label{subsubsec:preprocessing}
    Since we are building models based on both handcrafted features and on the string embedding, we need to preprocess the data differently.
    In the directory \texttt{data\textbackslash convert}, we provide a script \texttt{dill\_to\_csv.py} to convert the dill dataset from the integer array format to a textual URL format.
    The result is stored in \texttt{data\textbackslash csv\textbackslash (test/train/val).csv}.
    The other script \texttt{csv\_to\_feature\_vector.py} converts this csv from textual URL format to a feature vector using the feature selection described in \Cref{subsec:establishement-of-the-feature-vector}.
    The results are stored in \texttt{data\textbackslash feature\_vector\textbackslash (k)\textbackslash (test\_x/train\_x/val\_x).csv} where is k refers to the k in top k selected features.

    \subsection{Machine Learning Frameworks}
    For the machine learning framework, we decided to use RAPIDS AI’s cuML over sklearn due to its significant performance advantages when dealing with large datasets.
    Leveraging the GPU, cuML achieves a 10 to 50 times speedup compared to CPU-bound libraries like sklearn.
    Unlike sklearn, which operates primarily on CPUs and can struggle with scalability, cuML is designed to handle vast amounts of data more efficiently.
    Additionally, its API mirrors that of sklearn, offering ease of use and a familiar environment for those accustomed to sklearn, but with the added benefit of GPU acceleration.
    This makes cuML an attractive choice for projects without the need for extensive adjustment to new programming paradigms.

    The framework does not provide solutions to perform hyperparameter optimization, so we picked another library called hyperopt for this.
    Hyperopt is a powerful and versatile library for hyperparameter optimization in machine learning algorithms.
    Hyperopt employs Bayesian optimization, specifically the Tree of Parzen Estimators (TPE) algorithm, which stands out for its efficiency in navigating the hyperparameter space.
    Unlike the exhaustive search approach used in sklearn's GridSearchCV or the randomness of RandomizedSearchCV, Hyperopt's method is more focused and informed, learning from each iteration to concentrate on the most promising hyperparameter combinations.
    Optuna is another library that offers similar features.
    Hyperopt was a more appropriate choice for this project due to our experience with it and its ability to serve all our hyperparameter needs.

    Since most of the tested Machine Learning algorithms are quick and require little memory, we used hyperopt's \texttt{MongoTrials} to parallelize the parameter search.
    A simple Docker Compose yaml file is provided.

    \subsection{Deep Learning Frameworks}
    For the deep learning framework, we decided to use Keras due to its simplicity and ease of use.
    Although Keras is known for integrating with TensorFLow, the new Keras 3.0 API also supports other backends.
    Throughout the project, we switched backends multiple times, but we ultimately settled on using PyTorch.
    Using the dedicated GPU in our laptops, the PyTorch backend had the most predictable performance and memory and was the easiest to debug.
    By using such a high level framework, we were able to quickly iterate on different architectures and hyperparameters, rather than focusing on the implementation details of the neural networks.
    For instance, Keras provides simple callbacks to save the best model, and to stop training early if the validation loss does not improve for a certain number of epochs.
    It also provides built-in metric functions, such as accuracy, precision, recall, and F1 score.


    \section{ML models based on handcrafted features}\label{sec:models-based-on-handcrafted-features}

    Why considering approaches that relies on handcrafted features?
    because we want to use ML techniques, not only neural networks.
    + because it enables to reduce the dimension of the data, so to have a faster treatment and analysis afterwards.
    Intuitively, the information contained by an URL should be encoded into a far smaller dimension, which is what we try to reproduce by establishing a feature vector.
    Goal for us is to reduce from one dimension for each character for the biggest URL to one dimension for each interesting information only (ideally we would like each feature to represent one base vector onto the vector space encoding the information).
    In practice, we will try to find meaningful features that brings the best possible results, so there will be information loss.
    However, we can efficiently reduce the number of dimension
    - it reduces the number of information and introduces human intervention, which is bad in general because it introduces biases or lost of information.

    \subsection{Establishment of the feature vector}\label{subsec:establishement-of-the-feature-vector}

    TTo start, we're creating a feature vector from URLs - this is our first step in using stats to identify phishing sites.
    We've picked various features based on existing research, but we've left out those that need complex language processing.
    Also, we've added some new features we thought would be useful.

    We know some of these features might overlap or be more useful than others.
    Our plan is to figure out which features are really important and then narrow them down to keep only the best ones for spotting phishing URLs.

    \subsubsection{Computations of different features}

    \begin{table}[H]
        \centering
        \begin{tabular}{|c|l|p{6cm}|c|c|c|c|}
            \hline
            \textbf{No.} & \textbf{Feature Name}    & \textbf{Feature Description}                        & \textbf{Chi Score} & \textbf{Chi Ranking} & \textbf{Info Gain Score} & \textbf{Source} \\ \hline
            1            & Number of Dots           & Number of `.' in the URL                            & 64216.34           & 10                   & 0.0944                   & \cite{LexicalFeatureSelection}                  \\ \hline
            2            & Number of Hyphens        & Number of `-' in the URL                            & 517655.65          & 2                    & 0.0747                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            3            & Number of @              & Number of `@' in the URL                            & 4465.27            & 16                   & 0.0022                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            4            & Number of ?              & Number of `?' in the URL                            & 9006.72            & 13                   & 0.0129                   & \cite{LexicalFeatureSelection}                  \\ \hline
            5            & URL Length               & Length of the URL                                   & 291038.97          & 4                    & 0.0283                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            6            & Number of Digits         & Number of digits in the URL                         & 312225.09          & 3                    & 0.1280                   &                                                 \\ \hline
            7            & Number of /              & Number of `/' in the URL                            & 25682.89           & 12                   & 0.0621                   & \cite{LexicalFeatureSelection}                  \\ \hline
            8            & Number of //             & Number of `//' in the URL                           & 194.38             & 21                   & 0.1334                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            9            & Use of HTTPS             & Counts occurrences of `https'                       & 164109.06          & 5                    & 0.1230                   & \cite{PhishSafe}                                \\ \hline
            10           & Use of HTTP              & Counts occurrences of `http'                        & 215.22             & 20                   & 0.1470                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            11           & Use of WWW               & Counts occurrences of `www'                         & 1150.42            & 19                   & 0.0482                   &                                                 \\ \hline
            12           & IP Address Usage         & 1 if IP address is used, 0 otherwise                & 19994.97           & 14                   & 0.0113                   &                                                 \\ \hline
            13           & Suspicious Word Count    & Counts suspicious words in the URL                  & 517281.65          & 1                    & 0.1526                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            14           & TLD Position             & Position of Top-Level Domain in URL                 & 19567              & 15                   & 0.0                      & \cite{PhishSafe}                                \\ \hline
            15           & Path Length Ratio        & Ratio of path length to URL length                  & 64                 & 23                   & 0.0867                   & \cite{LexicalFeatureSelection}                  \\ \hline
            16           & Suspicious Char Count    & Counts suspicious characters in URL                 & 96221.30           & 9                    & 0.0510                   & \cite{LexicalFeatureSelection}                  \\ \hline
            17           & Symbol as Last Char      & 1 if the last character is a symbol, 0 otherwise    & 0                  & 24                   & 0.0 & \cite{LexicalFeatureSelection} \\ \hline
            18           & Redirection Count        & Counts the number of `.' in subdomain               & 264180             & 6                    & 0.0400                   &                                                 \\ \hline
            19           & IP Address Presence      & 1 if IP address present, 0 otherwise                & 19912              & 17                   & 0.0102                   & \cite{PhishSafe} \cite{LexicalFeatureSelection} \\ \hline
            20           & Subdomain Count          & Number of subdomains                                & 67397              & 11                   & 0.1247                   & \cite{PhishSafe}                                \\ \hline
            21           & Port Presence            & 1 if port number present, 0 otherwise               & 385                & 22                   & 0.0                      & \cite{LexicalFeatureSelection}                  \\ \hline
            22           & Unicode Char Count       & Number of unicode characters                        & 290705.11          & 7                    & 0.0279                   & \cite{LexicalFeatureSelection}                  \\ \hline
            23           & Query Presence           & 1 if query present in the URL, 0 otherwise          & 0                  & 25                   & 0.0                      & \cite{LexicalFeatureSelection}                  \\ \hline
            24           & Special Char Ratio       & Ratio of special characters to URL length           & 559.19             & 8                    & 0.0867                   &                                                 \\ \hline
            25           & Misspelled Word Presence & 1 if the URL contains misspelled words, 0 otherwise & 9199.83            & 18                   & 0.1170                   &  personal                                               \\ \hline
        \end{tabular}
        \caption{Summary of Features Implemented for Phishing URL Detection}
        \label{tab:features}
    \end{table}


    Some features have been designed by ourselves after reading on phishing.
    For example, because gift cards are a lot target by phishing attacks, we decided add a criteria to check whether the URL contains words like gift cards with different spelling.
    In our training dataset, it represents 200 URL.
    We also added a custom parameters that checks whether the URL contains misspelling using fuzzywuzzy import process and the similarity to a list of common misspelled names in URL

    Not use of some features proposed by the articles like:
    \begin{itemize}
        \item DNS lookup from\cite{PhishSafe} because we want to avoid the DNS call
        \item Inconsistent URL: If the domain name of suspicious web page is not matched
        with the WHOIS database record, then the web page is considered as phishing from\cite{PhishSafe}
        \item Age of Domain: If the age of website is less than 6 month, then chances of fake
        web page are more from\cite{PhishSafe}
    \end{itemize}
    The three firsts features have not been chosen because they require additional information than the URL itself

    \subsubsection{Filtering for working with the most relevant features}

    We expect some of them to be correlated, and some of them to be irrelevant.
    To improve our method in terms of computation speed as well as interpretability, we want to keep only the most relevant features.
    As provided in\cite{LexicalFeatureSelection}, we expect only a small number of features to be improve the accuracy.
    As showed on their graph below, above a threshold, the accuracy of their model do not increase anymore with the number of features used.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{report_img/lexicalfeatureselectionaccuracygraph}
        \caption{Feature wise accuracy of classifiers from\cite{LexicalFeatureSelection}}
        \label{fig:}
    \end{figure}

    Lots of different methods exist to select the most relevant features, among them:
    \begin{itemize}
        \item Principal Component Analysis (PCA)
        \item Singular Value Decomposition (SVD)
        \item Variance Thresholding
        \item Chi-Square
        \item Information Gain
    \end{itemize}

    In the context of feature selection for binary classification of phishing URLs, we examined the advantages and disadvantages of Principal Component Analysis (PCA), Singular Value Decomposition (SVD), Variance Thresholding, Chi-Square, and Information Gain.
    Choice has been made to consider these methods as they are the most frequently encountered.

    PCA is a dimensionality reduction method.
    It is interesting in our context were numerous features may be related.
    However, we decided to discard it because:
    \begin{enumerate}
        \item we loose the interpretability of the features, which is the main motive behind handcrafted features.
        \item the encoding of a new URL for testing it is more complex, compared to feature selection.
        Therefore, we loose the practicality of the approach.
    \end{enumerate}
    This solution is more interesting for high dimensional data, and data where the different meanings of the features do not matter.

    The same reasons also applies to singular value decomposition, that transforms the encoding of the features as well.

    We then examined Variance Thresholding, however we have two types of features: binary, and counts.
    Even if we normalize all features between zero and one, the variance is influenced by the nature of the feature.

    Our attention then shifted to Information Gain, as demonstrated in\cite{EfficientDeepLearningPhishingDetection} for feeding into neural networks.
    While Information Gain excels in measuring entropy reduction and is effective with both categorical and continuous variables, it falls short in capturing the correlation between features since it assesses them in isolation.

    This led us to Chi-Square, used in\cite{LexicalFeatureSelection}, a method renowned for its effectiveness in assessing the relevance of categorical features in classification tasks.
    Chi-square score is computed using the observed and expected frequencies of the features following the formula:
    \begin{equation}
        \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}\label{eq:equation}
    \end{equation}
    where \( \chi^2 \) is the Chi-Square statistic, \( O_i \) is the observed frequency, and \( E_i \) is the expected frequency under the null hypothesis that the feature and the target are independent.

    Chi-Square quantifies the independence, or lack thereof, between categorical variables and the target variable, offering a straightforward and computationally efficient approach for binary classification.

    Considering these factors, Chi-Square emerged as the most appropriate technique for our study.
    Its simplicity, efficiency, and focus on categorical feature relevance align well with the nature of our dataset and the objectives of our phishing URL classification project.


%    @Jop TODO add a graph on the influence of the number of parameters that we keep on the performance of the different models for one or several easy ML models + conclusion on the number k used afterwards, with comments on the shape and what it says on using chi square as a feature selection
    % @Jop TODO add graph for IG and conclude on our choice

    \subsubsection{Implementation}\label{subsubsec:implementation}

    % table with the recap of all hyper parameters, the ranges that have been tried and the best values obtained?

    \subsection{Motivation between the choices of the different machine learning models}\label{subsec:motivation-between-the-choices-of-the-different-machine-learning-models2}

    Different statistical approaches has been chosen to model our binary classification problem, as well linear than non linear models.
    We relied on the literature to chose the different models, as we want to replicate them and have a transversal comparison of the different models.
    Moreover, we also wanted to have a good coverage of the different types of models, to have a good overview of the different approaches and their performances.
    We also wanted to have models that made sens for our problem, and it was important for us to detail the strength and weaknesses of each model, to have a good understanding of the results that we obtained, and provide the reader with a good understanding of the different models, and the reason of the application in this problem.

    \subsubsection{Logistic Regression}
    We wanted to implement a simple model to have a baseline for the performance of the other models.
    Its easy implementation makes it a practical model for experimenting.
    It also provides a good interpretability of the results.

    \subsubsection{Support Vector Machine}\label{subsubsec:support-vector-machine}
    Idea behind the choice of Support Vector Machine was to chose a non linear kernel, and to have a model that provides non linear decision boundaries using the kernel trick.
    However, for optimization reasons, we were forced to chose to use a linear kernel, because it is the fastest to train on our dataset using scikit-learn, and the only available method using cumul.
    We then find analog results from the logistic regression, but we run it as a test to check that this implementation and linear regression are both coherent.

    \subsubsection{Naives Bayes}

    Naive Bayes is a linear classifier as well.
    It relies on the assumption of independence between the features.
    Even though we try through our feature selection to select features that are the least correlated, we expect some correlation.
    Therefore, we expect this model to perform worse than the previous ones.
    In addition, empirical studies like\cite{MLmodelsComparison} shows that this model in general performs worse than other models.
    However, it is interesting to verify this hypothesis.
    We seek to see how much worse it is in our comparison, to compare our results with some of the studies that uses it.
    As precised in\cite{NaiveBayesBackground}, \"As we observed before, the strength of feature dependencies (i.e. the class-conditional mutual information between the features) ’ignored’ by naive Bayes is not a good predictor of its classification error\".
    Therefore, the results on this classification do not enable us to measure efficiently the efficiency of our feature selection, like we would have wished.
    A better indicator for the performance of the Naive Bayes, as proposed in\cite{NaiveBayesBackground}, would be to use the information gain, which would be less efficient than the chi square, as explained earlier. % TODO add performances of the models using information gain k best features rather than chi score

    \subsubsection{Nearest neighbours}

    Motivation of this implementation is to have a first simple model that provides non linear decision boundaries.
    Performance of this model really relies on how good the initialization is.
    However, we can ask Python in built library to work on trying to find this best initialization.
    Interesting with this model is also the interpretability that it could provide for further studies.

    \subsubsection{Kernel Ridge Regression}
    % TODO to remove?
    Because non linear Support Vector Machine algorithm (using the kernel trick) was not available on cuml, we decided to try kernel ridge regression function, with adapting it to binary classification thanks to a threshold.
    The different kernel functions that are available, and that we tested are:
    \begin{enumerate}
        \item linear
        \item additive\_chi2
        \item chi2
        \item cosine
        \item laplacian
        \item polynomial
        \item poly
        \item rbf
        \item sigmoid
    \end{enumerate}

    \subsubsection{Random Forest}
    Random Forest is a non linear classifier for comparison of performances of at least two non linear usual classifiers.
    From\cite{MLmodelsComparison}, it is a model that in general has good performances.
    They are not likely to overfit on our big set of data.
    Provide a measure of feature importance, which is interesting for us to compare with our feature selection is relevant.
    Easy to train in parallel, which is interesting for our set up, and handle large datasets easily.
    % TODO: remove the last sentence or give a ranking of the most important features according to this model, or conslude that it could be used in further studies to improve the feature selection

    \subsection{Results}\label{subsec:results}

    % TODO complete with the results of the different models

    \begin{table}[H]
        \centering
        \begin{tabular}{|l|p{8cm}|l|}
            \hline
            \textbf{Model}          & \textbf{Best Hyperparameters}                                                                                                                          & \textbf{Accuracy} \\ \hline
            Logistic Regression     & c: 59.6435, class\_weight: 1, fit\_intercept: 0, l1\_ratio: 0.2014, penalty: 1, tol: 9.25e-05 & 82.54\% \\ \hline
            Linear SVC              & c: 16.3815, change\_tol: 0.000636, class\_weight: 1, fit\_intercept: 0, grad\_tol: 0.000487, loss: 1, penalized\_intercept: 0, penalty: 0, tol: 11.882 & 82.53\% \\ \hline
            Naive Bayes             & alpha: 0.1270, fit\_prior: 0                                                                                                                           & 71.35\%           \\ \hline
            Nearest Neighbors       & (No hyperparameters optimized)                                                                                                                         & 92.61\%           \\ \hline % TODO add hyperparameters
            Kernel Ridge Regression & alpha: 2.7303, coef0: 6.7390, degree: 6, gamma: 8.3768, kernel: 1 & 44.08\% \\ \hline
        \end{tabular}
        \caption{Comparison of Machine Learning Models for Phishing URL Detection}
        \label{tab:model_comparison}
    \end{table}
    % TODO use of different metrics than accuracy? Like Positive Rate (TPR), True Negative Rate (TNR), Accuracy (ACC), Precision (PRE) and F-Score (FSC), recall, \ldots + comment on which one is the most interesting in our case (we don't want to miss any fishing website, so we prefer to have a high recall, even if it means having a lower precision).
    % TODO comments and explain the results, for example on the risk of overfit

    %    \textbf{True Positive Rate (TPR) or Sensitivity or Recall:}
    %    \[
    %    TPR = \frac{TP}{TP + FN}
    %    \]
    %
    %    \textbf{True Negative Rate (TNR) or Specificity:}
    %    \[
    %    TNR = \frac{TN}{TN + FP}
    %    \]
    %
    %    \textbf{Accuracy (ACC):}
    %    \[
    %    ACC = \frac{TP + TN}{TP + TN + FP + FN}
    %    \]
    %
    %    \textbf{Precision (PRE) or Positive Predictive Value (PPV):}
    %    \[
    %    PRE = \frac{TP}{TP + FP}
    %    \]
    %
    %    \textbf{F-Score (FSC) or F1-Score:}
    %    \[
    %    FSC = \frac{2 \times PRE \times TPR}{PRE + TPR}
    %    \]

    Comparison of our results with the literature:

    \cite{LexicalFeatureSelection} Using Random Forest on Lexical features of URL 276640 98.57, Precision 97.63%
    \cite{LexicalFeatureSelection} Using Naive Bayes on Lexical features of URL 276640 82.46
    \cite{LexicalFeatureSelection} Using Naive Bayes on Lexical features of URL 276640 93.21
    \cite[]{PhishSafe} on 10 000 URL Naive Bayes 64.74
    \cite[]{PhishSafe} on 10 000 URL SVM 76.04
    \cite[]{PhishSafe} on 25 000 URL Naives Bayes 76.87
    \cite[]{PhishSafe} on 25 000 URL SVM 91.28
    \cite{NLPPhishingURLDetection} Random Forest 97.2 using additional NLP and wordtovec techniques to reach 278 features vector, dataset:73,575 URLs including 37,175 malicious URLs and 36,400 legal URLs.
    \cite{NLPPhishingURLDetection} Naïve Bayes 75.5 using additional NLP and wordtovec techniques to reach 278 features vector, dataset: 73,575 URLs including 37,175 malicious URLs and 36,400 legal URLs.


    \section{Deep Learning Models based on handcrafted features}\label{sec:deep-learning-models}

    \subsection{Motivation between the choices of the different machine learning models}\label{subsec:motivation-between-the-choices-of-the-different-machine-learning-models}
    For comparing with the first statistical models, we chose to implement different neural network architecture.
    Moreover, we wanted to compare the performance of our model with\cite{EfficientDeepLearningPhishingDetection}, using feature vectors on the URL and additional information, that achieves impressive accuracy results of over 99\% accuracy, more than the CNN model on character level embedding proposed by\cite{CharacterLevelCNN} the same year.

    \subsubsection{Dense neural network}
    Reasons for choosing this model:
    Simple neural network for serving as a baseline for the other models.

    \begin{lstlisting}[language=Python, caption=DNN on feature vector architecture]
        model = keras.Sequential(
            [
                layers.InputLayer(input_shape=(number_of_features,)),
                layers.Dense(units=256, activation="relu"),
                layers.Dense(units=128, activation="relu"),
                layers.Dense(units=64, activation="relu"),
                layers.Dense(units=32, activation="relu"),
                layers.Dense(units=1, activation="sigmoid"),
            ]
        )
    \end{lstlisting}

    \subsubsection{Convolutional neural network}
    Reasons for choosing this model:
    - Comparison with CNN on character level
    - Another simple architecture to compare with the other models
    However, we do not expect this model to perform as good as the other models because of the reduced sized of our feature vector.
    CNN models are usually used for finding patterns in images or other big dimension data that have spatial arrangement or hierarchy.

    \begin{lstlisting}[language=Python, caption=CNN on feature vector architecture]
        model = keras.Sequential(
            [
                layers.Reshape((number_of_features, 1), input_shape=(number_of_features,)),
                layers.Conv1D(filters=32, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Conv1D(filters=16, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Conv1D(filters=128, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Conv1D(filters=256, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Conv1D(filters=512, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Conv1D(filters=1024, kernel_size=3, activation="tanh"),
                layers.BatchNormalization(),
                layers.MaxPooling1D(pool_size=2),
                layers.Flatten(),
                layers.Dense(units=500, activation="tanh"),
                layers.Dense(units=1, activation="sigmoid"),
            ]
        )
    \end{lstlisting}

    \subsubsection{Long Short Term memory}
    Reasons for choosing this model:
    - LSTMs excel at learning long-term dependencies, which is beneficial if the relationship between features in the vector and the classification outcome extends over multiple features or if the context.
    Despite the relatively small size of the feature vector, complex interactions between features might exist.
    LSTMs can model these complex interactions more effectively than simpler models like dense neural networks.


    \begin{lstlisting}[language=Python, caption=LSTM on feature vector architecture]
        model = keras.Sequential(
            [
                # input shape to change because of the change of interpretation of the features
                layers.Reshape((number_of_features, 1), input_shape=(number_of_features,)),
                layers.LSTM(units=number_of_features, return_sequences=True),
                layers.LSTM(units=number_of_features, return_sequences=True),
                layers.LSTM(units=number_of_features, return_sequences=True),
                layers.LSTM(units=number_of_features, return_sequences=False),
                layers.Dense(units=1, activation="sigmoid"),
            ]
        )
    \end{lstlisting}

    \subsection{Results}\label{subsec:results2}
    @Jop for running the algorithm and providing the results + comment above on improvements on the implementation if needed


    \section{Models based on the string embedding}\label{sec:models-based-on-the-string-embedding}

    \subsection{Character level convolutional neural network}\label{subsec:character-level-convolutional-neural-network}

    \subsubsection{Motivation behind character level embedding}

    In the domain of phishing URL detection, the decision to utilize character-level embedding in a Convolutional Neural Network (CNN) model is grounded in several pivotal considerations.
    URLs often consist of arbitrarily constructed words or deliberately misspelled variations intended to impersonate legitimate websites.
    Traditional word-level embeddings face significant challenges here, particularly in encoding these misspellings distinctly from the original words and managing the \'Out of Vocabulary' (OOV) problem inherent to word embedding models.
    Although existing literature predominantly concentrates on models robust to misspellings, such approaches are not congruent with our objective, which is to detect and differentiate these errors, not to adapt to them.
    One article focuses on understanding the social meaning of common misspelling\cite{OOVmispelling}.
    Interesting for us, is that they compare different embeddings with regards to spelling robustness like fastText, which is a word embedding model that does take spelling into account, in opposition to skip gram.
    A viable approach is proposed in\cite{WordCharacterEmbeddings}with a model that combines word and character level embedding.
    However, for our problem, we expect the model to mostly rely on the character level embedding, since the words are random.

    To circumvent these limitations, character-level embedding emerges as a more suitable solution.
    It preserves the nuanced composition of these randomly assembled words, a critical factor in phishing detection, and obviates the need for a uniform treatment of diverse OOV words.

    Because we chose to rely on character embedding and to choose a dataset that already is encoded, we used the character-level embedding provided in\cite{CharacterLevelCNN}.

    \subsubsection{Motivation behind CNN architecture}

    The choice of a CNN architecture for this application is justified by several attributes:
    \begin{enumerate}
        \item \textbf{Local Patterns}: CNNs excel in identifying local patterns within data.
        In the context of character-level embeddings, this allows the network to discern specific character sequences indicative of phishing URLs.
        \item \textbf{Hierarchical Feature Learning}: The architecture enables the learning of hierarchical feature representations.
        Through convolutional and pooling layers, it can abstract higher-level features from character arrangements, potentially revealing complex character interrelations.
        \item \textbf{Translation Invariance}: CNNs are adept at handling variations in the position of key features, a valuable trait for analyzing URLs where relevant character patterns may shift in position.
        \item \textbf{Dimensionality Reduction}: The pooling layers in CNNs contribute to the reduction of feature dimensionality, honing in on the most pertinent information.
        \item \textbf{Efficiency on GPU}: CNNs offer computational efficiency, particularly on GPU setups.
    \end{enumerate}

    \subsubsection{Implementation}
    % @Jop TODO speak about the implementation/optimization for running
    Structure of the CNN comes from\cite{CharacterLevelCNN}, the study that provides the dataset that we are using.
    Interesting for us in replicating the algorithm of a study on their same dataset is to provide a comparison with the previous model and CNN implemented earlier with similar computing resources.

    Here is the structure of our model:
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\linewidth]{report_img/cnn_configuration}
        \caption{CNN on character level embedding architecture}
        \label{fig:CNN}
    \end{figure}

    \subsubsection{Results}

    \subsection{Large language model fine tuning}\label{subsec:large-language-model-finetuning}

    \subsubsection{Motivation of this implementation}
    @Jop complete
    Personal motivation to want to play with LLM. As well, it is a very recent approach, and we wanted to see how it performs on this problem.
    Moreover, few studies have been done on this approach, so we found it interesting to propose our new approach and modeling.

    \subsubsection{Implementation}

    \subsubsection{Results}


    \section{Conclusion}\label{sec:conclusion}
    % TODO the conclusion

    Bla bla on the contribution that this work brings and how nice and original it is
    Further perspectives

    Interpretability on the ransom forest to understand how classification is made? and how to improve it?

    Possibility to run the experiments on a new dataset.
    For example, we could try to generate a new dataset by crawling the web, or by using the PhishTank API.

    Further improvements and study to improve the detection?

    Extract from another paper for ideas:
    Machine learning-based methods are generally fast and
effective. They cope well with zero-hour attacks and allow
on-the-fly detection of phishing web pages. Nevertheless, the
performance of these methods varies and mainly depends on
the features extracted from web pages and on the composition
of the training datasets. In general, features extracted from
page URL are obtained quickly, although they are vulnerable
to URL manipulations. On the contrary, features extracted
from page source codes are robust to the evasion techniques
implemented by attackers, even though page downloads are
needed to obtain these features, thus causing delays and safety
issues. Despite these issues, machine learning models are
a valid and promising solution for detecting phishing web
pages.
    An important research gap refers to the increased use by
attackers of URL shortening services that mask the real phishing
URLs. These short URLs create an additional challenge
to list-based approaches and in particular to the management
of blacklists. Similarly, these URLs affect machine learningbased
approaches since most URL features suggested in the
literature become meaningless in this context, thus making
the detection mechanisms fail.

    Need to retrain the algorithm regularuly to have the detection up to date, performance decrease with time

Model explainability is another interesting research direction
in the context of machine learning. In fact, understanding
the decisions taken by machine learning algorithms, that is,
what characteristics make a web page phishing or legitimate,
has several important implications for the design of security
systems. Adversarial attacks should also be investigated to
make the machine learning models more robust.
It is also important to outline that, to ensure the advancement
of the state of the art, experiments should be made reproducible.
This means that all implementation details should
be clearly specified and the datasets used should be made
publicly available.

    Importance of public datasets to reproduce the issues

    Possibility to build an online website to check phishing through this detection method to help customers in the daily life ahead of their implementation

    \bibliographystyle{plain}
    \bibliography{refs}

\end{document}